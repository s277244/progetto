{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_cifar import resnet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper\n",
    "LR = 1e-2\n",
    "WEIGHT_DECAY = 0.00001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 70\n",
    "DEVICE = 'cuda'\n",
    "N=100\n",
    "NB_CL=10\n",
    "K=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iCarl(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(iCarl,self).__init__()\n",
    "        self.feature_extractor = resnet32()\n",
    "        self.feature_extractor.fc = nn.Linear(self.feature_extractor.fc.in_features, num_classes)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.dist_loss = nn.BCELoss()\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_known = 0\n",
    "        self.exemplars_sets = []\n",
    "    def __classifyNME__(self,net,data,exemplars):\n",
    "        print('NME')\n",
    "        mean_exemplars = dict.fromkeys(np.arange(n_classes))\n",
    "        net.eval() #turn off gradient computations\n",
    "        #compute mean\n",
    "        for k in exemplars:\n",
    "            exemplar_loader=DataLoader(exemplars[k],shuffle=True, batch_size=BATCH_SIZE,drop_last=True, num_workers=4)\n",
    "            mean=torch.zeros((1,64),device=DEVICE)\n",
    "            for image,_,_ in exemplar_loader:\n",
    "                with torch.no_grad():\n",
    "                    images=images.to(self.device)\n",
    "                    outputs=net(images,features=True)\n",
    "                    for out in outputs:\n",
    "                        mean += outputs\n",
    "            mean_exemplars=mean/mean.norm()/len(exemplars[key]) \n",
    "        dataloader=DataLoader(data,shuffle=True,batch_size=BATCH_SIZE, drop_last=True, num_workers=4)\n",
    "        correct = 0\n",
    "       \n",
    "        #prediction\n",
    "        for image,labels,_ in dataloader:\n",
    "            images=images.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                outputs = net(images,features=True)\n",
    "                outputs = outputs.to(DEVICE)\n",
    "                pred=[]\n",
    "                for out in outputs:\n",
    "                    for k in mean_exemplars:\n",
    "                        dist=torch.dist\n",
    "                        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.feature_extractor(x)\n",
    "        return x\n",
    "    \n",
    "    #TODO\n",
    "    def __classify__(self,x):\n",
    "        #compute exemplars mean\n",
    "        mean_exemplars=[]\n",
    "        for exemplars in self.exemplars_set:\n",
    "            features=[self.feature_extractor(ex) for ex in exemplars ]\n",
    "            media=np.mean(features)\n",
    "            mean_exemplars.append(media)\n",
    "        \n",
    "        phi_x=self.feature_extractor(x)\n",
    "        distances=np.sqrt([(phi_x-mean)**2 for mean in exemplars_mean])\n",
    "        nearest=np.argmin(distances)\n",
    "        \n",
    "        return nearest   \n",
    "    \n",
    "    def combine_dataset_with_exemplars(self, dataset):\n",
    "        for y, P_y in enumerate(self.exemplar_sets):\n",
    "            exemplar_images = P_y\n",
    "            exemplar_labels = [y] * len(P_y)\n",
    "            dataset.append(exemplar_images, exemplar_labels)\n",
    "    \n",
    "    def update_representation(self,data):\n",
    "        #X : training images of classes s...t\n",
    "        #exemplar_sets P_1,P_(s-1)\n",
    "        # theta : current model parameters\n",
    "        \n",
    "              \n",
    "        #incremen classes\n",
    "        classes = list(set(data.train_labels))\n",
    "        n = [cls for cls in classes if cls > self.num_classes - 1] #new classes\n",
    "        \n",
    "        input_f=self.feature_extractor.fc.in_features\n",
    "        out_f=self.feature_extractor.fc.out_features\n",
    "        weight = self.feature_extractor.fc.weight.data\n",
    "        bias = self.feature_extractor.fc.bias.data\n",
    "        \n",
    "        \n",
    "        self.feature_extractor.fc = nn.Linear(in_features, out_features+n, bias=False)\n",
    "        self.feature_extractor.fc.weight.data[:out_features] = weight\n",
    "        self.feature_extractor.fc.bias.data[:out_features] = bias\n",
    "        self.num_classes += n\n",
    "        \n",
    "       #self.to(DEVICE)\n",
    "        \n",
    "        print('{} new classes'.format(len(list(set(self.targets)))))\n",
    "        #TODO\n",
    "        #form combined training sets   \n",
    "        D=data\n",
    "        \n",
    "        dataloader = DataLoader(D, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "        print('Store network outputs with pre-update parameters')\n",
    "        q = torch.zeros(len(dataset), self.n_classes).to(DEVICE)\n",
    "        for images,labels,indexes in dataloader:\n",
    "            images = images.to(DEVICE)\n",
    "            indexes = indexes.to(DEVICE)\n",
    "            \n",
    "            g=F.sigmoid(self.forward(images))\n",
    "            q[indexes]=g.data\n",
    "        q.to(DEVICE)\n",
    "        \n",
    "        #network training\n",
    "        for epoch in range(1,NUM_EPOCHS+1):\n",
    "            for i,(images,labels, indexes) in enumerate(dataloader):\n",
    "                \n",
    "                images,labels=images.to(DEVICE),labels.to(DEVICE)\n",
    "                indexes=indexes.to(DEVICE)\n",
    "                #zero_grad: we need to set the gradients to zero before starting to do backpropragation\n",
    "                #because PyTorch accumulates the gradients on subsequent backward passes.\n",
    "                optimizer.zero_grad()\n",
    "                output = self.forward(images)\n",
    "                #classification loss new classes\n",
    "                loss = self.loss(output, labels)\n",
    "                # Distilation loss for old classes\n",
    "                if self.num_known > 0:\n",
    "                    g = F.sigmoid(g)\n",
    "                    q_i = q[indices]\n",
    "                    dist_loss = sum(self.dist_loss(g[:,y], q_i[:,y]) for y in range(self.num_known))\n",
    "                    #dist_loss = dist_loss / self.n_known\n",
    "                    loss += dist_loss\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                           %(epoch+1, NUM_EPOCHS, i+1, len(dataset)//BATCH_SIZE, loss.data[0]))\n",
    "                    \n",
    "    def __construct_exemplar_set(self,images,m):\n",
    "        #m target number of exemplars\n",
    "        #images of class y\n",
    "        #feature function=self.feature_extractor\n",
    "        features=[]\n",
    "        for img in images:\n",
    "            img.to(DEVICE)\n",
    "            feature=self.feature_extractor(img)\n",
    "            features.append(feature)\n",
    "        features=np.array(features)\n",
    "        \n",
    "        current_class_mean=np.mean(features)\n",
    "        \n",
    "        exemplar_set=[]\n",
    "        exemplar_feature=[]\n",
    "        for k in range(1,m+1):\n",
    "            exemplar_sum = np.sum(exemplar_features)\n",
    "            somma=float(exemplar_sum+features)/(k)\n",
    "            \n",
    "            p_k=np.argmin(np.sqrt([(current_class_mean-c)**2 for c in somma]))\n",
    "            \n",
    "            exemplar_set.append(images[p_k])\n",
    "            exemplar_feature.append(features[p_k])\n",
    "            \n",
    "            features = np.delete(features, i) #####????\n",
    "            \n",
    "        self.exemplar_set=exemplar_set\n",
    "        \n",
    "    def __reduce_exemplar_set(self,m):\n",
    "        #m taget number of exemplars\n",
    "        #input : current exemplar set\n",
    "        \n",
    "        #keep only first m for each class\n",
    "        for y, P_y in enumerate(self.exemplar_sets):\n",
    "            self.exemplar_sets[y] = P_y[:m]\n",
    "        \n",
    "   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from dataset import CIFAR10, CIFAR100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    N = images.shape[0]\n",
    "    fig = plt.figure(figsize=(1, N))\n",
    "    gs = gridspec.GridSpec(1, N)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "TOT_CLASSES= 100\n",
    "NUM_CL = 10\n",
    "K = 2000 #num of exemplars\n",
    "DEVICE='cuda'\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarl=iCarl\n",
    "icarl.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(0, TOT_CLASSES, NUM_CL):\n",
    "    train_dataset = CIFAR100(root='data/', classes=range(s,s+num_classes), train=True, download=True, transform=train_transform)\n",
    "    test_dataset = CIFAR100(root='data/', classes=range(s,s+num_classes),  train=False, download=True, transform=test_transform)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=0)\n",
    "    \n",
    "    #update via backprop\n",
    "    icarl.update_representation(train_set)\n",
    "    m=int(K/icarl.num_classes)\n",
    "    \n",
    "    @TODO\n",
    "    # Reduce exemplar sets for known classes\n",
    "    \n",
    "    # Construct exemplar sets for new classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n",
      "range(10, 20)\n",
      "range(20, 30)\n",
      "range(30, 40)\n",
      "range(40, 50)\n",
      "range(50, 60)\n",
      "range(60, 70)\n",
      "range(70, 80)\n",
      "range(80, 90)\n",
      "range(90, 100)\n"
     ]
    }
   ],
   "source": [
    "for s in range(0, TOT_CLASSES, NUM_CL):\n",
    "    print(range(s,s+NUM_CL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.zeros(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=40\n",
    "b=10\n",
    "c=2\n",
    "a=a/b\n",
    "d=a/c\n",
    "\n",
    "#del d\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=40\n",
    "b=10\n",
    "c=2\n",
    "a/b/c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementazione paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar100 import CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class splits\n",
    "range_classes = np.arange(100)\n",
    "classes= np.array_split(range_classes, 10)\n",
    "\n",
    "for iteration in range(N/NB_CL):\n",
    "    #save results each increment\n",
    "    \n",
    "    #prepare data for current batch\n",
    "    train_dataset = CIFAR100(root='data/', classes=classes[i], train=True, download=True, transform=train_transform)\n",
    "    test_dataset = CIFAR100(root='data/', classes=classes[i],  train=False, download=True, transform=test_transform)\n",
    "    \n",
    "    #add stored exemplars to training\n",
    "    \n",
    "    #training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        #shuffle training\n",
    "        \n",
    "        #for batch\n",
    "        \n",
    "        #distillation\n",
    "        if iteration>0:\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
