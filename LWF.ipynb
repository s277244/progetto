{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from resnet_cifar import resnet32\n",
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "LR = 0.1\n",
    "WEIGHT_DECAY = 1e-5\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 5\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_normal_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='sigmoid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWF(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LWF,self).__init__()\n",
    "        self.model = resnet32()\n",
    "        self.model.apply(kaiming_normal_init)\n",
    "        self.model.fc = nn.Linear(64, num_classes) # Modify output layers\n",
    "\n",
    "# Save FC layer in attributes\n",
    "        self.fc = self.feature_extractor.fc\n",
    "        # Save other layers in attributes\n",
    "        self.feature_extractor = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        self.feature_extractor = nn.DataParallel(self.feature_extractor) \n",
    "\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.dist_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        # n_classes is incremented before processing new data in an iteration\n",
    "        # n_known is set to n_classes after all data for an iteration has been processed\n",
    "        self.n_classes = 0\n",
    "        self.n_known = 0\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    def increment_classes(self, new_classes):\n",
    "        \"\"\"Add n classes in the final fc layer\"\"\"\n",
    "        n = len(new_classes)\n",
    "        print('new classes: ', n)\n",
    "        in_features = self.fc.in_features\n",
    "        out_features = self.fc.out_features\n",
    "        weight = self.fc.weight.data\n",
    "\n",
    "        if self.n_known == 0:\n",
    "            new_out_features = n\n",
    "        else:\n",
    "            new_out_features = out_features + n\n",
    "        print('new out features: ', new_out_features)\n",
    "        self.model.fc = nn.Linear(in_features, new_out_features, bias=False)\n",
    "        self.fc = self.model.fc\n",
    "\n",
    "        kaiming_normal_init(self.fc.weight)\n",
    "        self.fc.weight.data[:out_features] = weight\n",
    "        self.n_classes += n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
